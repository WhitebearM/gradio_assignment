{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_recognition as sr\n",
    "import pymysql\n",
    "import openai\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from wordcloud import WordCloud\n",
    "from pydub import AudioSegment\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from deep_translator import GoogleTranslator\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #openai_api_key\n",
    "# openai.api_key = \"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\"\n",
    "\n",
    "#모델 초기화\n",
    "model = ChatOllama(model=\"gemma2\", temperature= 0.7, verbose= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#번역 함수\n",
    "def translate_to_korean(text):\n",
    "    translated = GoogleTranslator(source='en', target=\"ko\").translate(text)\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 설명 생성 함수\n",
    "def generate_image_description(image):\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs)\n",
    "    caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image):\n",
    "    \"\"\"\n",
    "    이미지를 입력받아 설명을 생성하고 한국어로 번역하는 함수\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        return \"이미지를 업로드해주세요.\"\n",
    "    \n",
    "    try:\n",
    "        # 이미지 설명 생성\n",
    "        description = generate_image_description(image)\n",
    "        \n",
    "        # 설명을 한국어로 번역\n",
    "        translated_description = translate_to_korean(description)\n",
    "        \n",
    "        return translated_description\n",
    "    except Exception as e:\n",
    "        return f\"이미지 분석에 실패했습니다: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#챗봇\n",
    "def chat(message, history):\n",
    "    chat_history = []\n",
    "    for human, ai in history:\n",
    "        chat_history.append(HumanMessage(content=human))\n",
    "        chat_history.append(AIMessage(content=ai))\n",
    "    \n",
    "    if message:\n",
    "        chat_history.append(HumanMessage(content=message))\n",
    "        response = model.invoke(chat_history)\n",
    "        \n",
    "             # 반환값이 AIMessage인 경우 문자열로 변환\n",
    "        if hasattr(response, \"content\"):\n",
    "            return response.content  # 문자열 반환\n",
    "        else:\n",
    "            return str(response)  # 예상치 못한 경우 문자열로 변환\n",
    "    \n",
    "    return \"메시지를 입력해주세요.\"\n",
    "        \n",
    "    # chat_history.append(HumanMessage(content=message))\n",
    "    # response = model.invoke(chat_history)\n",
    "        \n",
    "    # return response\n",
    "    #위코드는 반환되면서 객체로 반환 그래서 에러나는거였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(uploaded_file):\n",
    "    if uploaded_file is not None:\n",
    "        try:\n",
    "            file_path = uploaded_file.name\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "        except Exception as e:\n",
    "            return f\"파일 처리 중 오류: {e}\", None\n",
    "    else:\n",
    "        return \"텍스트 파일을 업로드해주세요.\", None\n",
    "\n",
    "    if not text.strip():\n",
    "        return \"텍스트 파일이 비어 있습니다.\", None\n",
    "\n",
    "    # 워드 클라우드 생성\n",
    "    wordcloud = WordCloud(\n",
    "        font_path='C:/Windows/Fonts/malgun.ttf',  # 한글 폰트 경로\n",
    "        background_color='white',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        max_words=200\n",
    "    ).generate(text)\n",
    "\n",
    "    # 이미지를 로컬 파일로 저장\n",
    "    output_path = \"wordcloud.png\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    # os.remove(output_path)\n",
    "\n",
    "    return \"워드 클라우드가 성공적으로 생성되었습니다.\", output_path\n",
    "\n",
    "def clean_up_image(image_path):\n",
    "    \"\"\"이미지 파일 삭제\"\"\"\n",
    "    if os.path.exists(image_path):\n",
    "        os.remove(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(uploaded_audio):\n",
    "    if uploaded_audio is None:\n",
    "        return \"오디오 파일을 업로드해주세요.\"\n",
    "\n",
    "    # SpeechRecognition을 사용하여 음성 텍스트 변환\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        # 업로드된 오디오 파일 경로 가져오기\n",
    "        audio_path = uploaded_audio.name\n",
    "     \n",
    "             # WAV로 변환\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "        wav_path = \"temp.wav\"\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "        print(\"[DEBUG] 파일이 WAV 형식으로 변환되었습니다.\")\n",
    "\n",
    "        # SpeechRecognition으로 변환\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(wav_path) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_data, language=\"ko-KR\")\n",
    "        \n",
    "        # 변환 후 임시 파일 삭제\n",
    "        os.remove(wav_path)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"음성을 인식할 수 없습니다.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"STT 서비스에 문제가 발생했습니다: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mysql DB연결 설정\n",
    "# def connect_to_db():\n",
    "#     connection = pymysql.connect(\n",
    "#         host=\"localhost\",\n",
    "#         user=\"root\",\n",
    "#         password=\"1234\",\n",
    "#         database=\"test\",\n",
    "#         charset=\"utf8mb4\",\n",
    "#         cursorclass=pymysql.cursors.DictCursor  # 결과를 딕셔너리 형태로 반환\n",
    "#     )\n",
    "#     return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def execute_query(query):\n",
    "#     connection = connect_to_db()\n",
    "#     try:\n",
    "#         with connection.cursor() as cursor:\n",
    "#             cursor.execute(query)\n",
    "#             results = cursor.fetchall()\n",
    "#         return results\n",
    "#     finally:\n",
    "#         connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 허깅페이스 text-to-sql 모델 로드\n",
    "# # text_to_sql = pipeline(\"text2sql\", model=\"microsoft/table-transformer-text-to-sql\")\n",
    "\n",
    "# def natural_language_to_sql(natural_language, table_schema):\n",
    "#     \"\"\"\n",
    "#     자연어를 SQL로 변환하는 함수\n",
    "#     \"\"\"\n",
    "#     # 프롬프트 작성\n",
    "#     prompt = f\"\"\"\n",
    "#     테이블 스키마:\n",
    "#     {table_schema}\n",
    "\n",
    "#     아래 자연어 질문을 적절한 SQL 쿼리로 변환하세요:\n",
    "#     질문: \"{natural_language}\"\n",
    "#     SQL:\n",
    "#     \"\"\"\n",
    "\n",
    "#     # OpenAI API 호출\n",
    "#     response = openai.Completion.create(\n",
    "#         engine=\"text-davinci-003\",  # GPT-3.5 또는 GPT-4\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=150,\n",
    "#         temperature=0.3\n",
    "#     )\n",
    "#     return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\gradio_assignment\\.venv\\lib\\site-packages\\gradio\\components\\chatbot.py:279: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#탭공간\n",
    "with gr.Blocks() as iface:\n",
    "    with gr.Tab(\"무물보\"):\n",
    "        demo = gr.ChatInterface(\n",
    "            fn = chat,\n",
    "            examples=[\n",
    "                \"안녕하세요!\",\n",
    "                \"오늘의 저녁을 추천해주세요\",\n",
    "                \"대한민국 인원은 몇명인가요?\"\n",
    "            ],\n",
    "            title = \"AI챗봇\",\n",
    "            description=\"무엇이든 물어보세요!\"\n",
    "        )\n",
    "        \n",
    "    with gr.Tab(\"이미지 분석\"):\n",
    "        with gr.Row():\n",
    "            image_input = gr.Image(type=\"pil\", label=\"이미지를 업로드해주세요\")\n",
    "            \n",
    "        submit_button = gr.Button(\"분석\")\n",
    "        output_text = gr.Textbox(lines=5, label=\"결과\")\n",
    "        \n",
    "        submit_button.click(\n",
    "            fn=analyze_image,\n",
    "            inputs=[image_input],\n",
    "            outputs=output_text,\n",
    "        )\n",
    "        \n",
    "    with gr.Tab(\"wordCloud\"):\n",
    "        gr.Markdown(\"텍스트를 입력하거나 파일을 업로드 해주세요\")\n",
    "        \n",
    "        upload_file = gr.File(label=\"파일 업로드\", file_types=['.txt'])\n",
    "        output_image = gr.Image(label=\"워드 클라우드 결과\")\n",
    "        output_massage = gr.Textbox(label=\"결과 메세지\", interactive=False)\n",
    "        generate_btn = gr.Button(\"결과 생성\")\n",
    "    \n",
    "        generate_btn.click(\n",
    "            fn=generate_wordcloud,\n",
    "            inputs=[upload_file],\n",
    "            outputs=[output_massage,output_image],\n",
    "        )\n",
    "        \n",
    "        generate_btn.click(\n",
    "            fn=lambda upload_file: clean_up_image(\"wordcloud.png\"),\n",
    "            inputs=[upload_file],\n",
    "            outputs=[],\n",
    "        )\n",
    "        \n",
    "    with gr.Tab(\"음성 텍스트 반환\"):\n",
    "        gr.Markdown(\"MP3파일을 업로드 해주세요\")\n",
    "        audio_file = gr.File(label=\"오디오 파일 업로드\", file_types=[\".wav\",\".mp3\"])\n",
    "        output_text = gr.Textbox(label=\"변환된 텍스트\")\n",
    "        transcribe_btn = gr.Button(\"반환 시작\")\n",
    "        \n",
    "        transcribe_btn.click(\n",
    "            fn = transcribe_audio,\n",
    "            inputs= [audio_file],\n",
    "            outputs=[output_text]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iface' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43miface\u001b[49m\u001b[38;5;241m.\u001b[39mlaunch(server_port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7989\u001b[39m, server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iface' is not defined"
     ]
    }
   ],
   "source": [
    "iface.launch(server_port=7989, server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 파일이 WAV 형식으로 변환되었습니다.\n",
      "[DEBUG] 파일이 WAV 형식으로 변환되었습니다.\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
